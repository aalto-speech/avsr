{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of model changes\n",
    "\n",
    "The [DAVEnet model](https://github.com/dharwath/DAVEnet-pytorch) (Harwath et al. 2018) had two precursor models:\n",
    "\n",
    "[NIPS 2016 model](https://papers.nips.cc/paper/6186-unsupervised-learning-of-spoken-language-with-visual-context.pdf) and [ACL 2017 model](https://arxiv.org/pdf/1701.07481.pdf)\n",
    "\n",
    "Code for these two models was not published, but they could be recreated using DAVEnet as a basis. This notebook documents the differences found between these three models to help the replicating process.\n",
    "\n",
    "## Comparison table\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;border:none;border-color:#ccc;margin:0px auto;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 9px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 9px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}\n",
    ".tg .tg-waok{font-weight:bold;font-family:Tahoma, Geneva, sans-serif !important;;border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-td0d{font-family:\"Lucida Sans Unicode\", \"Lucida Grande\", sans-serif !important;;text-align:left;vertical-align:top}\n",
    ".tg .tg-j6ou{background-color:#f9f9f9;font-family:\"Lucida Sans Unicode\", \"Lucida Grande\", sans-serif !important;;text-align:left;vertical-align:top}\n",
    "@media screen and (max-width: 767px) {.tg {width: auto !important;}.tg col {width: auto !important;}.tg-wrap {overflow-x: auto;-webkit-overflow-scrolling: touch;margin: auto 0px;}}</style>\n",
    "<div class=\"tg-wrap\"><table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-waok\">Model part</th>\n",
    "    <th class=\"tg-waok\">NIPS2016 Model</th>\n",
    "    <th class=\"tg-waok\">ACL 2017 Model</th>\n",
    "    <th class=\"tg-waok\">DAVEnet ECCV 2018</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Image input</td>\n",
    "      <td class=\"tg-j6ou\">Subtract VGG mean pixel value (no mention of variance/std) and take a <i>center</i> 224x224 crop.</td>\n",
    "    <td class=\"tg-td0d\">Presumably the same as NIPS.</td>\n",
    "    <td class=\"tg-j6ou\">Resize smallest dimension to 256, take a <i>random</i> 224x224 crop and normalize with global mean and variance.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Image body</td>\n",
    "    <td class=\"tg-j6ou\">A VGG16 with softmax classification layer removed. VGG weights presumed to be fixed (not specified in the paper).</td>\n",
    "    <td class=\"tg-td0d\">The same as NIPS, weights are known to be fixed.</td>\n",
    "    <td class=\"tg-j6ou\">A VGG16 where the last maxpool and all layers after that are replaced with one convolution layer.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Image output</td>\n",
    "    <td class=\"tg-j6ou\">Linear transform of the 4096 inputs from the penultimate layer to 1024 dimensions.</td>\n",
    "    <td class=\"tg-td0d\">The same as NIPS.</td>\n",
    "    <td class=\"tg-j6ou\">A 3 by 3 linear convolution which outputs a 1024 feature map.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Audio input</td>\n",
    "    <td class=\"tg-j6ou\">Log Mel filter bank spectrograms with 40 filters. Spectrogram normalization. Fixed to L frames (=1024/<b>2048</b>, latter is better) using truncation or zero padding.</td>\n",
    "    <td class=\"tg-td0d\">The same as NIPS, but only L=1024 considered.</td>\n",
    "    <td class=\"tg-j6ou\">Similar to NIPS, but with following changes. Samples are padded to the length of the longest caption in a minibatch. Manual spectrogram normalization is replaced by a BatchNorm layer.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Audio body</td>\n",
    "    <td class=\"tg-j6ou\">3 convolution layers with ReLU, 2 maxpools, 1 mean- or maxpool and a L2 normalization.</td>\n",
    "    <td class=\"tg-td0d\">5 convolution layers with ReLU, 3 maxpools, a meanpool and a L2 normalization.</td>\n",
    "    <td class=\"tg-j6ou\">Similar to ACL, but there is BatchNorm layer at the front. Also L2 normalization removed from the end.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Audio output</td>\n",
    "    <td class=\"tg-j6ou\">1024 dimensional activation vector.</td>\n",
    "    <td class=\"tg-td0d\">The same as NIPS.</td>\n",
    "    <td class=\"tg-j6ou\">1024 dimensional feature map. The padding is removed at this stage, individually for each caption</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Parameters</td>\n",
    "      <td class=\"tg-j6ou\">SGD, 50 epochs, <i>constant</i> momentum 0.9, minibatch size 128. Learning rate: 1e-5, geometrical decay by a factor between 2 and 5 every 5 to 10 epochs.</td>\n",
    "    <td class=\"tg-td0d\">The same as NIPS.</td>\n",
    "    <td class=\"tg-j6ou\">The same as NIPS except models converged in less than 150 epoch on average. Learning rate: 1e-3, decay by factor of 10 in every 70 epochs. </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-td0d\">Similarity function</td>\n",
    "    <td class=\"tg-j6ou\">Dot product</td>\n",
    "    <td class=\"tg-td0d\">Dot product</td>\n",
    "      <td class=\"tg-j6ou\">SISA, <b>MISA</b> (best), SIMA</td>\n",
    "  </tr>\n",
    "</table></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "9.2.148\n",
      "7600\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# For importing the models folder\n",
    "import sys\n",
    "sys.path.append('/m/home/home4/44/virkkua1/unix/PlacesAudio_project/DAVEnet')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as tvmodels\n",
    "from torchsummary import summary\n",
    "\n",
    "import models\n",
    "\n",
    "# The last line prints False, then there's something funny with Cuda toolkit installation. \n",
    "# For example the toolkit might have been updated without updating the driver which\n",
    "# leads to mismatch and errors.\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.backends.cudnn.enabled)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIPS model\n",
    "\n",
    "Trying to replicate the NIPS model using the DAVEnet base and the table of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvX3AudioNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024):\n",
    "        super(ConvX3AudioNet, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(40,5), stride=(1,1), padding=(0,2))\n",
    "        self.conv2 = nn.Conv2d(64, 512, kernel_size=(1,25), stride=(1,1), padding=(0,12))\n",
    "        self.conv3 = nn.Conv2d(512, 1024, kernel_size=(1,25), stride=(1,1), padding=(0,12))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1,4), stride=(1,2), padding=(0,1))\n",
    "        self.globalPool = nn.MaxPool2d(kernel_size=(1,256), stride=(1,1), padding=(0,0))\n",
    "        self.fc = nn.Linear(1024, 205)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.normalize(self.globalPool(x), dim=1)\n",
    "        x = x.squeeze()\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "convX3 = ConvX3AudioNet()\n",
    "convX3.cuda()\n",
    "summary(convX3, (40, 1024), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16withFC(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024):\n",
    "        super(VGG16withFC, self).__init__()\n",
    "        seed_model = tvmodels.__dict__['vgg16'](pretrained=True)\n",
    "        # Remove last 1000-dim class transform\n",
    "        seed_model.classifier = nn.Sequential(*list(seed_model.classifier.children())[:-1])\n",
    "        # Freeze params\n",
    "        for param in seed_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Add a linear transform of the embedding dimension size\n",
    "        last_layer_index = len(list(seed_model.classifier.children()))\n",
    "        seed_model.classifier.add_module(str(last_layer_index),\n",
    "                                         nn.Linear(4096, embedding_dim))\n",
    "        self.image_model = seed_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.image_model(x)\n",
    "        return x\n",
    "\n",
    "vgg16witbhFC = VGG16withFC()\n",
    "vgg16withFC.cuda()\n",
    "summary(vgg16withFC, (3, 224, 224), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup for DAVEnet audio branch\n",
    "\n",
    "Embedding models are difficult to train from scratch. Tuomas said that it is therefore general practice to warmup/pretrain the embedding model weights using a simpler classification task. In this section I write a classifier version of the DAVEnet audio branch. It tries to predict the Places image class of the audio captions. The image branch of the DAVEnet uses conventional image classifiers like VGG16 or ResNet50. For these pretrained weights already exist and are available in Torch. \n",
    "\n",
    "The image classes are extracted from the image paths of the Places400k dataset. For this, see the \"create_class_labels\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DavenetClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024):\n",
    "        super(DavenetClassifier, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batchnorm1 = nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(40,1), stride=(1,1), padding=(0,0))\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=(1,11), stride=(1,1), padding=(0,5))\n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=(1,17), stride=(1,1), padding=(0,8))\n",
    "        self.conv4 = nn.Conv2d(512, 512, kernel_size=(1,17), stride=(1,1), padding=(0,8))\n",
    "        self.conv5 = nn.Conv2d(512, embedding_dim, kernel_size=(1,17), stride=(1,1), padding=(0,8))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1,3), stride=(1,2),padding=(0,1))\n",
    "        self.fc = nn.Linear(64*embedding_dim, 205)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        print(x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1, 1024 * (self.embedding_dim // 2**4))\n",
    "        print(x.shape)\n",
    "        x = x.squeeze()\n",
    "        print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class_model = DavenetClassifier()\n",
    "class_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(class_model, (40, 2048), batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResDAVEnet\n",
    "\n",
    "DAVEnet got a new version with residual connections, described in the paper [\"Transfer Learning from Audio-Visual Grounding to Speech Recognition\"](https://arxiv.org/pdf/1907.04355.pdf).\n",
    "\n",
    "Here I attempt to replicate the ResDAVEnet model using the DAVEnet base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard resnet34 for comparison\n",
    "standard_resnet = tvmodels.resnet34()\n",
    "standard_resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.29\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 180.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(standard_resnet, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResDAVEnet has 1x9 convolutions instead of 3x3\n",
    "def conv1x9(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x9 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=(1,9), stride=stride,\n",
    "                     padding=(0, 4), bias=False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "# This BasicBlock is an adjusted version of the one defined in torch example implementation of ResNet:\n",
    "# https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x9(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1x9(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResDaveNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim=1024):\n",
    "        super(ResDaveNet, self).__init__()\n",
    "        \n",
    "        self._norm_layer = nn.BatchNorm2d\n",
    "        self.inplanes = 128\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(40, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.batchnorm1 = self._norm_layer(self.inplanes)\n",
    "\n",
    "        self.stack1 = self._make_residual_block(BasicBlock, 128, 2, stride=2)\n",
    "        self.stack2 = self._make_residual_block(BasicBlock, 256, 2, stride=2)\n",
    "        self.stack3 = self._make_residual_block(BasicBlock, 512, 2, stride=2)\n",
    "        self.stack4 = self._make_residual_block(BasicBlock, 1024, 2, stride=2)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_residual_block(self, block, planes, blocks, stride=1):\n",
    "        \n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = self.stack1(x)\n",
    "        x = self.stack2(x)\n",
    "        x = self.stack3(x)\n",
    "        x = self.stack4(x)\n",
    "        \n",
    "        x = x.squeeze(2)\n",
    "        return x\n",
    "    \n",
    "    # Allow for accessing forward method in a inherited class\n",
    "    forward = _forward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResDavenet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(40, 1), stride=(1, 1))\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (stack1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 9), stride=(2, 2), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (stack2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(1, 9), stride=(2, 2), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (stack3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(1, 9), stride=(2, 2), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (stack4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(512, 1024, kernel_size=(1, 9), stride=(2, 2), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resDAVE = ResDavenet()\n",
    "resDAVE.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 128, 1, 1024]           5,248\n",
      "              ReLU-2         [-1, 128, 1, 1024]               0\n",
      "       BatchNorm2d-3         [-1, 128, 1, 1024]             256\n",
      "            Conv2d-4          [-1, 128, 1, 512]         147,456\n",
      "       BatchNorm2d-5          [-1, 128, 1, 512]             256\n",
      "              ReLU-6          [-1, 128, 1, 512]               0\n",
      "            Conv2d-7          [-1, 128, 1, 512]         147,456\n",
      "       BatchNorm2d-8          [-1, 128, 1, 512]             256\n",
      "              ReLU-9          [-1, 128, 1, 512]               0\n",
      "           Conv2d-10          [-1, 128, 1, 512]          16,384\n",
      "      BatchNorm2d-11          [-1, 128, 1, 512]             256\n",
      "             ReLU-12          [-1, 128, 1, 512]               0\n",
      "       BasicBlock-13          [-1, 128, 1, 512]               0\n",
      "           Conv2d-14          [-1, 128, 1, 512]         147,456\n",
      "      BatchNorm2d-15          [-1, 128, 1, 512]             256\n",
      "             ReLU-16          [-1, 128, 1, 512]               0\n",
      "           Conv2d-17          [-1, 128, 1, 512]         147,456\n",
      "      BatchNorm2d-18          [-1, 128, 1, 512]             256\n",
      "             ReLU-19          [-1, 128, 1, 512]               0\n",
      "             ReLU-20          [-1, 128, 1, 512]               0\n",
      "       BasicBlock-21          [-1, 128, 1, 512]               0\n",
      "           Conv2d-22          [-1, 256, 1, 256]         294,912\n",
      "      BatchNorm2d-23          [-1, 256, 1, 256]             512\n",
      "             ReLU-24          [-1, 256, 1, 256]               0\n",
      "           Conv2d-25          [-1, 256, 1, 256]         589,824\n",
      "      BatchNorm2d-26          [-1, 256, 1, 256]             512\n",
      "             ReLU-27          [-1, 256, 1, 256]               0\n",
      "           Conv2d-28          [-1, 256, 1, 256]          32,768\n",
      "      BatchNorm2d-29          [-1, 256, 1, 256]             512\n",
      "             ReLU-30          [-1, 256, 1, 256]               0\n",
      "       BasicBlock-31          [-1, 256, 1, 256]               0\n",
      "           Conv2d-32          [-1, 256, 1, 256]         589,824\n",
      "      BatchNorm2d-33          [-1, 256, 1, 256]             512\n",
      "             ReLU-34          [-1, 256, 1, 256]               0\n",
      "           Conv2d-35          [-1, 256, 1, 256]         589,824\n",
      "      BatchNorm2d-36          [-1, 256, 1, 256]             512\n",
      "             ReLU-37          [-1, 256, 1, 256]               0\n",
      "             ReLU-38          [-1, 256, 1, 256]               0\n",
      "       BasicBlock-39          [-1, 256, 1, 256]               0\n",
      "           Conv2d-40          [-1, 512, 1, 128]       1,179,648\n",
      "      BatchNorm2d-41          [-1, 512, 1, 128]           1,024\n",
      "             ReLU-42          [-1, 512, 1, 128]               0\n",
      "           Conv2d-43          [-1, 512, 1, 128]       2,359,296\n",
      "      BatchNorm2d-44          [-1, 512, 1, 128]           1,024\n",
      "             ReLU-45          [-1, 512, 1, 128]               0\n",
      "           Conv2d-46          [-1, 512, 1, 128]         131,072\n",
      "      BatchNorm2d-47          [-1, 512, 1, 128]           1,024\n",
      "             ReLU-48          [-1, 512, 1, 128]               0\n",
      "       BasicBlock-49          [-1, 512, 1, 128]               0\n",
      "           Conv2d-50          [-1, 512, 1, 128]       2,359,296\n",
      "      BatchNorm2d-51          [-1, 512, 1, 128]           1,024\n",
      "             ReLU-52          [-1, 512, 1, 128]               0\n",
      "           Conv2d-53          [-1, 512, 1, 128]       2,359,296\n",
      "      BatchNorm2d-54          [-1, 512, 1, 128]           1,024\n",
      "             ReLU-55          [-1, 512, 1, 128]               0\n",
      "             ReLU-56          [-1, 512, 1, 128]               0\n",
      "       BasicBlock-57          [-1, 512, 1, 128]               0\n",
      "           Conv2d-58          [-1, 1024, 1, 64]       4,718,592\n",
      "      BatchNorm2d-59          [-1, 1024, 1, 64]           2,048\n",
      "             ReLU-60          [-1, 1024, 1, 64]               0\n",
      "           Conv2d-61          [-1, 1024, 1, 64]       9,437,184\n",
      "      BatchNorm2d-62          [-1, 1024, 1, 64]           2,048\n",
      "             ReLU-63          [-1, 1024, 1, 64]               0\n",
      "           Conv2d-64          [-1, 1024, 1, 64]         524,288\n",
      "      BatchNorm2d-65          [-1, 1024, 1, 64]           2,048\n",
      "             ReLU-66          [-1, 1024, 1, 64]               0\n",
      "       BasicBlock-67          [-1, 1024, 1, 64]               0\n",
      "           Conv2d-68          [-1, 1024, 1, 64]       9,437,184\n",
      "      BatchNorm2d-69          [-1, 1024, 1, 64]           2,048\n",
      "             ReLU-70          [-1, 1024, 1, 64]               0\n",
      "           Conv2d-71          [-1, 1024, 1, 64]       9,437,184\n",
      "      BatchNorm2d-72          [-1, 1024, 1, 64]           2,048\n",
      "             ReLU-73          [-1, 1024, 1, 64]               0\n",
      "             ReLU-74          [-1, 1024, 1, 64]               0\n",
      "       BasicBlock-75          [-1, 1024, 1, 64]               0\n",
      "================================================================\n",
      "Total params: 44,671,104\n",
      "Trainable params: 44,671,104\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.16\n",
      "Forward/backward pass size (MB): 39.00\n",
      "Params size (MB): 170.41\n",
      "Estimated Total Size (MB): 209.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resDAVE, (40, 1024))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
