{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract class labels for PlacesAudio from Places205 image paths\n",
    "\n",
    "The audio-visual embeddings models of Harwath et al. that use PlacesAudio\n",
    "\n",
    "- [NIPS 2016 model](https://papers.nips.cc/paper/6186-unsupervised-learning-of-spoken-language-with-visual-context.pdf)\n",
    "- [ACL 2017 model](https://arxiv.org/pdf/1701.07481.pdf)\n",
    "- [DAVEnet model](https://github.com/dharwath/DAVEnet-pytorch)\n",
    "\n",
    "are difficult to train from scratch. Initial warm-up could help, but the audio data has no labels. However, the images paired with audio captions have been organized to classes that are visible in their path (e.g. `c/cottage_garden/gsun_c43911d6f8ff4efb5e99dc6ac7e47a8e.jpg`). In this notebook the aim is to extract the classes from the image paths to get classification labels for the audio. Each audio caption has one corresponding image and thus one label.\n",
    "\n",
    "First we define the function that can do the extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re           # Regexps for pattern matching\n",
    "import warnings     # Place warnings if any anomalies encountered\n",
    "\n",
    "# Function that does the extraction from an input file and writes the result to an output file\n",
    "# The 205 classes are supplied in the classes parameter\n",
    "def extract_classes(input_file_path, output_file_path, classes): \n",
    "    \n",
    "    print(\"Input json is {}\".format(input_file_path))\n",
    "    with open(input_file_path) as f:\n",
    "        inputs = json.load(f)\n",
    "        \n",
    "    for i in range(len(inputs[\"data\"])):\n",
    "        # Replace key \"image\" with \"label\"\n",
    "        inputs[\"data\"][i][\"label\"] = inputs[\"data\"][i].pop(\"image\")\n",
    "        # Find the class from the image path using regexp\n",
    "        match = re.search('[a-z]?\\/(.+)\\/gsun', inputs[\"data\"][i][\"label\"])\n",
    "        if match:\n",
    "            if match.group(1) in classes:\n",
    "                # Use an index number instead of the word label\n",
    "                inputs[\"data\"][i][\"label\"] = classes.index(match.group(1))\n",
    "            else:\n",
    "                warnings.warn(\"Did not find label '%s' among Places205 classes.\".format(match.group(1)))\n",
    "        else:\n",
    "            warnings.warn(\"Matching regexp to '%s' failed\".format(inputs[\"data\"][i][\"label\"]))\n",
    "    \n",
    "    print(\"Writing output to {}\\n\".format(output_file_path))\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(inputs, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform the extraction for different subsets of the PlacesAudio400k dataset. Each paper has one plus there is a shared validation dataset:\n",
    " - NIPS, ~116k samples, `nips_train.json`\n",
    " - ACL, ~214k samples, `acl_train.json`\n",
    " - DAVEnet, full PlacesAudio dataset of ~402k samples, `train.json` \n",
    " - Validation data, 1k samples), `val.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input json is /teamwork/t40511_asr/c/PlacesAudio400k/PlacesAudio_400k_distro/metadata/train1k.json\n",
      "Writing output to /teamwork/t40511_asr/c/PlacesAudio400k/PlacesAudio_400k_distro/metadata/classification_train1k.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/teamwork/t40511_asr/c/PlacesAudio400k/PlacesAudio_400k_distro/\"\n",
    "#input_and_output_files = [(\"metadata/nips_train.json\", \"metadata/classification_nips_train.json\"),\n",
    "#                          (\"metadata/nips_val.json\", \"metadata/classification_nips_val.json\"),\n",
    "#                          (\"metadata/acl_train.json\", \"metadata/classification_acl_train.json\"),\n",
    "#                          (\"metadata/acl_val.json\", \"metadata/classification_acl_val.json\"),\n",
    "#                          (\"metadata/train.json\", \"metadata/classification_train.json\"),\n",
    "#                          (\"metadata/val.json\", \"metadata/classification_val.json\")]\n",
    "input_and_output_files = [(\"metadata/train1k.json\", \"metadata/classification_train1k.json\")]\n",
    "\n",
    "\n",
    "# Get the 205 class names from a file, one class per line\n",
    "classes_file = \"metadata/Places205_classes.txt\"\n",
    "\n",
    "with open(data_path + classes_file) as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "for (input_file, output_file) in input_and_output_files:\n",
    "    extract_classes(data_path + input_file,\n",
    "                    data_path + output_file,\n",
    "                    classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
