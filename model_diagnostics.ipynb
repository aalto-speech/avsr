{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model diagnostics\n",
    "\n",
    "This notebook records good practices for effective deep learning model training and diagnostics. Covers the following topics:\n",
    "\n",
    "1. [First step: Output logs](#first-step-output-logs)\n",
    "2. [Second step: Log parsing](#second-step-log-parsing)\n",
    "3. [Third step: Informative plotting](#third-step-informative-plotting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: Output logs\n",
    "\n",
    "To understand how your model is doing, you need to collect data on its performance. Model output log files are the place for that. Often repeated advice regarding program logs of any sort can be summarised as \"log everything/the more you log the better\". But this is a difficult starting point, so here we'll list of the most important parameters and their uses as well as some general notes about good logs.\n",
    "\n",
    "*todo: logging frequency of different variables?*\n",
    "\n",
    "### Train/Validation/Test losses\n",
    "\n",
    "Losses are the most important variables to keep track of because tracking them will tell you how the model is learning. To get the full picture of how your model is doing, it is necessary to track both training and validation/test loss. Comparing training and test loss plotted with regards to epoch can show over-/underfitting phenomena. Plotting losses against learning rate can help choose correct learning rate value or boundaries. \n",
    "\n",
    "### Epochs and mini batches\n",
    "\n",
    "Including the current epoch and mini batches in logs is vital for informative plotting. The plots of different losses and accuracy usually have epochs as the x-axis, to show the \"*temporal*\" progress of the model makes.\n",
    "\n",
    "### Time\n",
    "\n",
    "Logging the time it takes to for example load data or train one batch can help with resource management. Time logs can point out clogs in your model pipeline. For instance GPUs might run idle if the data loading stage takes long. In this case, adding resources (CPU power) to preprocessing stage might help. Furthermore, if some step in the model training takes unreasonably long time, it might hint at a bug in the model code. \n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Accuracy (or similar statistic) is an important measurement of model performance. When an accuracy curve plateaus, it means the model training has converged and it is time to stop training.\n",
    "\n",
    "### Logging style\n",
    "\n",
    "When designing log output, always name clearly the values you are printing. Being verbose does not hurt, natural language and descriptive names can on the contrary help you identify variables at the next step. It is also a good idea to write down the units (seconds or milliseconds) and use tab delimiting in your logs to improve readability. Below are few example lines from a log and their Python style formatting strings.\n",
    "\n",
    "\n",
    "#### Log example\n",
    "```\n",
    "Epoch: [1][100/900]\tTime 0.486 (1.901)\tData 0.000 (1.394)\tLoss total 2.0161 (2.0171)\n",
    "Epoch: [1][200/900]\tTime 7.931 (1.892)\tData 7.389 (1.386)\tLoss total 1.9982 (2.0163)\n",
    "Epoch: [1][300/900]\tTime 0.489 (1.882)\tData 0.000 (1.379)\tLoss total 2.0468 (2.0176)\n",
    "Epoch: [1][400/900]\tTime 7.007 (1.886)\tData 6.521 (1.384)\tLoss total 2.0137 (2.0159)\n",
    "Epoch: [1][500/900]\tTime 0.540 (1.887)\tData 0.000 (1.385)\tLoss total 1.9612 (2.0161)\n",
    "```\n",
    "#### Formatting\n",
    "\n",
    "So how do you reproduce the logs above? Below is a minimal working example you can play with. The technical details of how Python formatting works is not the focus here (for that, see [this guide](https://pyformat.info/)). However, here are some general ideas from the code to keep in mind:\n",
    "\n",
    "1. Create a general class if you need to for example compute statistics of a variable (`AverageMeter`)\n",
    "2. Split your print to several lines to make your code readable for yourself and others\n",
    "3. Round your floats to 3-5 significant numbers (`.3f`)\n",
    "4. Use tab delimiters (`\\t`)\n",
    "5. You can supply objects and access their variables within the formatting string (`batch_time, data_time, loss_meter`, this is supported only in Python3)\n",
    "6. Set `flush=True` to ensure your prints are outputted right away\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/900]\tTime 0.750 (0.625)\tData 0.333 (0.267)\tLoss total 1.4969 (2.0437)\n"
     ]
    }
   ],
   "source": [
    "# An example of a convenience class for storing a class. You can freely modify this to track other statistics as well.\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "# Dummy values for the print command below\n",
    "epoch = 1\n",
    "i = 100\n",
    "train_loader = [0] * 900\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "loss_meter = AverageMeter()\n",
    "batch_time.update(0.500)\n",
    "batch_time.update(0.750)\n",
    "data_time.update(0.200)\n",
    "data_time.update(0.333)\n",
    "loss_meter.update(2.59053)\n",
    "loss_meter.update(1.49687)\n",
    "\n",
    "print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "      'Loss total {loss_meter.val:.4f} ({loss_meter.avg:.4f})'.format(\n",
    "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss_meter=loss_meter), flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step: Log parsing\n",
    "\n",
    "So now you have lot of logs, but how to efficiently get out the values you want? For example how to find from the previous log example the values after `Loss total`\n",
    "\n",
    "```\n",
    "Epoch: [1][100/900]\tTime 0.486 (1.901)\tData 0.000 (1.394)\tLoss total 2.0161 (2.0171)\n",
    "Epoch: [1][200/900]\tTime 7.931 (1.892)\tData 7.389 (1.386)\tLoss total 1.9982 (2.0163)\n",
    "Epoch: [1][300/900]\tTime 0.489 (1.882)\tData 0.000 (1.379)\tLoss total 2.0468 (2.0176)\n",
    "Epoch: [1][400/900]\tTime 7.007 (1.886)\tData 6.521 (1.384)\tLoss total 2.0137 (2.0159)\n",
    "Epoch: [1][500/900]\tTime 0.540 (1.887)\tData 0.000 (1.385)\tLoss total 1.9612 (2.0161)\n",
    "```\n",
    "and copying them into a separate file?\n",
    "```\n",
    "2.0161 (2.0171)\n",
    "1.9982 (2.0163)\n",
    "2.0468 (2.0176)\n",
    "2.0137 (2.0159)\n",
    "1.9612 (2.0161)\n",
    "\n",
    "```\n",
    "\n",
    "Fortunately there are several powerful command line tools that can help you parse your logs quickly after you understand their basic usage. The following subsections will cover regular expressions, `grep` and `sed`. First is a general programming tool for finding patterns in your text, latter two are command line utilities you can use to find and extract values from your logs. There is also a third command line tool, `awk`, which is a full programming language designed for text processing, but it will not be covered here.  \n",
    "\n",
    "### Regexp\n",
    "\n",
    "So you want to find something in a text file? If it is some literal word like *loss*, easy peasy. But what if it is something more complex? You are not looking for a particular word, but for all the numbers or special character in a text. Or all the numbers after a certain word. Essentially, you want to find patterns in the text. Regular expressions are a pattern matching tool designed to do just that. In practice, regular expressions are strings of special characters where each special character is a shorthand for some simple pattern. Combine them correctly and you can match complex patterns like social security numbers, phone numbers from different countries or time and date formats. You could even use regexp to ensure a password fulfills the requirements for a strong password! [More examples here](https://medium.com/factory-mind/regex-cookbook-most-wanted-regex-aa721558c3c1).\n",
    "\n",
    "To continue our running example, what is the regexp that will match to the words *Loss total* and the two floats after it? The answer is\n",
    "\n",
    "```\n",
    "/Loss total [0-9]*\\.[0-9]* \\([0-9]*\\.[0-9]*\\)/g\n",
    "```\n",
    "Let's break the expression into its constituents.\n",
    "\n",
    "1. The forward slashes `/.../` indicate the beginning and end of the regexp.\n",
    "2. The **g**lobal flag `g` at the end of the expression makes the search *global* that is the expression will match all instances of pattern not just that first it can find.\n",
    "3. `Loss total ` finds exact matches of *Loss total*.\n",
    "4. Square brackets `[...]` define a range. Here `[0-9]` means numbers ranging from 0 to 9.\n",
    "5. Asterisk `*` is a quantifier matching to 0 or more instances of the previous token. Here `[0-9]*` reads as *find 0 or more digits in the range from 0 to 9*.\n",
    "6. `\\.` matches to a literal dot character. Adding `\\` is necessary because dot alone refers to any character (except line breaks).\n",
    "7. `\\(` and `\\)` match to the literal parentheses characters because plain `(...)` has another function in regexps.\n",
    "\n",
    "To summarise, the example regexp can be read aloud as *match any instance of **Loss total** followed by a float which is followed by another float in parentheses*.\n",
    "\n",
    "*todo: add an image where the regexp is highlighted according to the above sentence*\n",
    "\n",
    "If you want to learn more about how to form regexp, [check this tutorial](https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285). Also, designing regexps can be hard, but luckily the internet has [interactive and graphical regexp editors](https://regexr.com/) you can use to check your regexps work. \n",
    "\n",
    "### Grep\n",
    "\n",
    "Now that we have a pattern, we need a tool where we can apply it. Say hello to `grep`. The short definition of `grep`, according to the documentation is\n",
    "> print lines matching a pattern\n",
    "\n",
    "A pattern can be just text if you want to find particular words in a log. But you can also supply regexps to `grep` with the `-E` option. The capital E stands for extend regular expressions which have some additional features when compared to the normal regular expressions (flag `-e`). So running the regexp `grep -E 'Loss total [0-9]*\\.[0-9]* \\([0-9]*\\.[0-9]*\\)' log_file.txt` on a log file containing the five example lines\n",
    "\n",
    "```\n",
    "Epoch: [1][100/900]\tTime 0.486 (1.901)\tData 0.000 (1.394)\tLoss total 2.0161 (2.0171)\n",
    "Epoch: [1][200/900]\tTime 7.931 (1.892)\tData 7.389 (1.386)\tLoss total 1.9982 (2.0163)\n",
    "Epoch: [1][300/900]\tTime 0.489 (1.882)\tData 0.000 (1.379)\tLoss total 2.0468 (2.0176)\n",
    "Epoch: [1][400/900]\tTime 7.007 (1.886)\tData 6.521 (1.384)\tLoss total 2.0137 (2.0159)\n",
    "Epoch: [1][500/900]\tTime 0.540 (1.887)\tData 0.000 (1.385)\tLoss total 1.9612 (2.0161)\n",
    "```\n",
    "will produce output where all the matches are highlighted. Note that in `grep` commands the forward slashes `/.../` indicating the beginning and end of a regexp are replaced with apostrophes `'...'`. Flags like `g` are also left out or replaced with options instead. Highlighting is nice, but what if we want to see only the matches and not the whole file? Adding the option `-o` to the command (`grep -oE 'Loss total [0-9]*\\.[0-9]* \\([0-9]*\\.[0-9]*\\)' log_file.txt`) will produce\n",
    "\n",
    "```\n",
    "Loss total 2.0161 (2.0171)\n",
    "Loss total 1.9982 (2.0163)\n",
    "Loss total 2.0468 (2.0176)\n",
    "Loss total 2.0137 (2.0159)\n",
    "Loss total 1.9612 (2.0161)\n",
    "```\n",
    "\n",
    "Nice! But if we want to copy the values here to plot them, we first have to remove each repetition of `Loss total` and the float in parentheses. While `grep` can print the matches (which is useful in many occasions), it is not exactly suited to print partial matches or to substitute parts of the output with other values. Furthermore, doing the removal manually would just be pain in the ass. Fortunately, there is another tool that can do just what we want. \n",
    "\n",
    "### Sed\n",
    "\n",
    "Meet `sed`. It is a flexible tool that can edit input streams/files in many ways (`sed` is short for **s**tream __ed__itor). The most important and popular editing tool in `sed` is the substitute command which takes the form `sed 's/one/ONE/'`. The four parts of the command are:\n",
    "\n",
    "```\n",
    "s          Substitute command\n",
    "/../../    Delimiter\n",
    "one        Regular Expression Search Pattern\n",
    "ONE        Replacement string\n",
    "```\n",
    "\n",
    "In short, the substitute command replaces any string matching to the regexp search pattern `one` with the replacement string `ONE`. Great! With small edits to regexp in our example, we can use the substitute command to do what the `grep` command could not. First change is to mark the portion we want to keep (the first float after `Loss total`). This can be done with escaped parentheses `\\(...\\)` signifying a capturing group. Confusingly enough, with `sed` escaped parentheses mark a capturing group while a lone parenthesis is interpreted as the character itself. Normally with regexps it goes the other way around. Parentheses `(...)` stand for a capturing group and you need to add an escape before literal parentheses in your pattern. The result of these changes is\n",
    " \n",
    "`/Loss total [0-9]*\\.[0-9]* \\([0-9]*\\.[0-9]*\\)/` $\\rightarrow$ `/Loss total \\([0-9]*\\.[0-9]*\\) ([0-9]*\\.[0-9]*)/`\n",
    "\n",
    "The problem with the current regexp is that `sed` will output the whole line where the match is found and replace only the matching part. So rest of the line will be included in the output unchanged. To avoid this, the second change is to add `.*` in the beginning and the end of the regexp to account for any characters preceding and following our match on the same line (`.*` reads *0 or more instances of any character*). This way the whole line is included in the match, because `sed` operates on a line-by-line basis. After the change we have\n",
    "\n",
    "`/Loss total \\([0-9]*\\.[0-9]*\\) ([0-9]*\\.[0-9]*)/` $\\rightarrow$ `/.*Loss total \\([0-9]*\\.[0-9]*\\) ([0-9]*\\.[0-9]*).*/`\n",
    "\n",
    "Now our regexp is ready for `sed`, but what to put in the replacement string? Easy! We will just have to put `\\1` there. `\\1`refers to the first capturing group i.e. the part that is inside `\\(...\\)`. If we had more capturing groups `\\(...\\)`, `\\2` would refer to the second capture group starting from left, `\\3` to the third etc. Since we only want the float we captured, nothing else is needed. Final form of `sed` command is thus\n",
    "\n",
    "`sed -n 's/.*Loss total \\([0-9]*\\.[0-9]*\\) ([0-9]*\\.[0-9]*).*/\\1/p' log_file.txt`\n",
    "\n",
    "The final touches to the command are the input file `log_file.txt`, the option `-n` and the command `p` at the end of the substitute command. **Without** the latter two, `sed` will output all the lines that do not match to the pattern *as is* in addition to the output from the substitute command. The option `-n` alone will suppress any output from `sed` (=no output). The print command `p` prints the result of the substitute command. Adding it alone will mean that the output of the substitute command is printed twice. Combine the two and `sed` will output only the result of the substitute command. Success! \n",
    "\n",
    "```\n",
    "2.0161\n",
    "1.9982\n",
    "2.0468\n",
    "2.0137\n",
    "1.9612\n",
    "```\n",
    "\n",
    "Similar to the regexp editor above, there is also an [online editor](https://sed.js.org/) for testing your `sed` commands. [Here](http://www.grymoire.com/Unix/Sed.html) is also a longer guide to `sed` commands for those needing it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step: Informative plotting\n",
    "\n",
    "### Learning rate search\n",
    "\n",
    "Learning rate is one of the most important hyperparameters in deep learning models. Just trying out different values might work, but here a good plot can be immensely helpful. Ideally, we would like to have plot like the one below:\n",
    "\n",
    "<img src=\"lr_finder.png\">\n",
    "\n",
    "Here the model has been trained for few epochs with a learning rate that changes logarithmically from a given minimum value to a given maximum value. The learning rates are then plotted against a loss, yielding the figure above. From the curve we can easily see, that the values near the minimum were too low because the loss curve stay flat. Then around the learning rate of 4e-4 the loss curve begins to drop dramatically, indicating that the model is learning something. After 1e-3 the curve starts oscillating wildly, telling us that that the learning rate is too big for the model to converge. Based on this, we can pick the initial learning rate from the good range, or use the good range itself in methods like CLR (cyclical learning rate).\n",
    "\n",
    "\n",
    "\n",
    "### Under- and overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
